{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['extent']\n",
    "categorical_features = ['growth_stage', 'damage', 'season']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "transformers_encoder_onehot = [\n",
    "    ('encoder', OneHotEncoder(), categorical_features)\n",
    "]\n",
    "column_transformer = ColumnTransformer(transformers_encoder_onehot, remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_encoded = column_transformer.fit_transform(dataset)\n",
    "dataset = pd.DataFrame(dataset_encoded, columns=column_transformer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names = [col.replace('encoder__', '').replace('remainder__', '') for col in column_transformer.get_feature_names_out()]\n",
    "dataset.columns = new_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>growth_stage_F</th>\n",
       "      <th>growth_stage_M</th>\n",
       "      <th>growth_stage_S</th>\n",
       "      <th>growth_stage_V</th>\n",
       "      <th>damage_DR</th>\n",
       "      <th>damage_DS</th>\n",
       "      <th>damage_FD</th>\n",
       "      <th>damage_G</th>\n",
       "      <th>damage_ND</th>\n",
       "      <th>damage_PS</th>\n",
       "      <th>damage_WD</th>\n",
       "      <th>damage_WN</th>\n",
       "      <th>season_LR2020</th>\n",
       "      <th>season_LR2021</th>\n",
       "      <th>season_SR2020</th>\n",
       "      <th>season_SR2021</th>\n",
       "      <th>filename</th>\n",
       "      <th>extent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L427F01330C01S03961Rp02052.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>L1083F00930C39S12674Ip.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24_initial_1_1463_1463.JPG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L341F00167C01S00324Rp14178.jpg</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>L1084F02394C39S13931Ip.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  growth_stage_F growth_stage_M growth_stage_S growth_stage_V damage_DR  \\\n",
       "0            0.0            0.0            1.0            0.0       0.0   \n",
       "1            0.0            0.0            0.0            1.0       0.0   \n",
       "2            0.0            0.0            0.0            1.0       0.0   \n",
       "3            0.0            1.0            0.0            0.0       1.0   \n",
       "4            0.0            0.0            0.0            1.0       0.0   \n",
       "\n",
       "  damage_DS damage_FD damage_G damage_ND damage_PS damage_WD damage_WN  \\\n",
       "0       0.0       0.0      0.0       0.0       0.0       1.0       0.0   \n",
       "1       0.0       0.0      1.0       0.0       0.0       0.0       0.0   \n",
       "2       0.0       0.0      1.0       0.0       0.0       0.0       0.0   \n",
       "3       0.0       0.0      0.0       0.0       0.0       0.0       0.0   \n",
       "4       0.0       0.0      1.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "  season_LR2020 season_LR2021 season_SR2020 season_SR2021  \\\n",
       "0           0.0           0.0           1.0           0.0   \n",
       "1           0.0           0.0           0.0           1.0   \n",
       "2           1.0           0.0           0.0           0.0   \n",
       "3           0.0           0.0           1.0           0.0   \n",
       "4           0.0           0.0           0.0           1.0   \n",
       "\n",
       "                         filename extent  \n",
       "0  L427F01330C01S03961Rp02052.jpg      0  \n",
       "1      L1083F00930C39S12674Ip.jpg      0  \n",
       "2      24_initial_1_1463_1463.JPG      0  \n",
       "3  L341F00167C01S00324Rp14178.jpg     60  \n",
       "4      L1084F02394C39S13931Ip.jpg      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeImg(path, size):\n",
    "    img = Image.open(path)\n",
    "\n",
    "    width, height = img.size\n",
    "    aspectRatio = width / height\n",
    "\n",
    "    if aspectRatio < 1:\n",
    "        nHeight = size\n",
    "        nWidth = int(size * aspectRatio)\n",
    "    else:\n",
    "        nWidth = size\n",
    "        nHeight = int(size / aspectRatio)\n",
    "\n",
    "    resizedImg = img.resize((nWidth, nHeight), Image.LANCZOS)\n",
    "\n",
    "    newImg = Image.new(\"RGB\", (size, size), (255, 255, 255))\n",
    "\n",
    "    xOffset = (size - nWidth) // 2\n",
    "    yOffset = (size - nHeight) // 2\n",
    "    newImg.paste(resizedImg, (xOffset, yOffset))\n",
    "\n",
    "    return newImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ruta donde se encuentran las imÃ¡genes\n",
    "image_path = \"data/train/\"\n",
    "image_size = 128\n",
    "output_file = \"resized_images.npy\"\n",
    "\n",
    "def load_and_resize_images(df, path, size):\n",
    "    images = []\n",
    "    for filename in tqdm(df['filename']):\n",
    "        img = resizeImg(os.path.join(path, filename), size)\n",
    "        img_array = np.array(img) / 255.0\n",
    "        images.append(img_array)\n",
    "    return np.array(images)\n",
    "\n",
    "# Verificar si ya existe el archivo .npy\n",
    "if not os.path.exists(output_file):\n",
    "    images = load_and_resize_images(dataset, image_path, image_size)\n",
    "    np.save(output_file, images)  # Guardar el archivo .npy\n",
    "else:\n",
    "    images = np.load(output_file)  # Cargar el archivo .npy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Cargar el modelo preentrenado VGG16\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
    "# Extraer las caracterÃ­sticas de la Ãºltima capa convolucional\n",
    "model = Model(inputs=base_model.input, outputs=base_model.layers[-1].output)\n",
    "\n",
    "# Extraer caracterÃ­sticas\n",
    "features = model.predict(images)\n",
    "# Aplanar las caracterÃ­sticas para usarlas en Random Forest\n",
    "features_flat = features.reshape(len(features), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las caracterÃ­sticas a un DataFrame y unir con el dataset original\n",
    "features_df = pd.DataFrame(features_flat)\n",
    "df_features = pd.concat([df.reset_index(drop=True), features_df], axis=1)\n",
    "df_features.drop(columns=[\"filename\"], inplace=True)  # Retirar la columna 'filename' ya que ahora tenemos las features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Dividir datos\n",
    "X = df_features.drop(columns=[\"extent\"])\n",
    "y = df_features[\"extent\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo Random Forest\n",
    "model_rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el modelo\n",
    "y_pred = model_rf.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowpy310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
